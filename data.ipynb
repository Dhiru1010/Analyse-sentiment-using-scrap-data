{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d08c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e8ddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How artificial intelligence can boost your pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does AI help to monitor Retail Shelf watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How are genetic sequencing maps affected by de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI and its impact on the Fashion Industry - Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benefits of Big Data in Different fields - Bla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  How artificial intelligence can boost your pro...\n",
       "1  How does AI help to monitor Retail Shelf watch...\n",
       "2  How are genetic sequencing maps affected by de...\n",
       "3  AI and its impact on the Fashion Industry - Bl...\n",
       "4  Benefits of Big Data in Different fields - Bla..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('E:/Blackoffer/Data.csv', encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e639fb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the punctuation and making lower case\n",
    "import string \n",
    "def punctuation_remove(str):\n",
    "    #fist two use for the replace the data\n",
    "    return str.translate(str.maketrans('\\xa0',' ',string.punctuation))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of data and calling function\n",
    "# here it can give chainedcopysetting error so you can supress using below line or use loc function to copy the data\n",
    "pd.options.mode.chained_assignment = None \n",
    "data=df.copy()\n",
    "for i in range(0,170):\n",
    "    data['text'][i] = punctuation_remove(data['text'][i]).lower()\n",
    "    data['text'][i] = ''.join([i for i in  data['text'][i] if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef83c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'impacts of covid  on food products  blackcoffer insightssome vendors fruit and vegetable sellers began venturing out after a few days without explicit permission and immediately faced police harassment after a few weeks the government eased restrictions and essential vendors were being permitted to vend due in large part to the advocacy of vendor organizations and activist networks however the cost of doing business as well as the risk has gone up significantly with vendors not having access to wholesale markets and suppliers and having to spend more on travel costs due to travel restrictions in place in the city also with the lockdown still partially in place the number of buyers has gone down and so have earnings due to the harsh summer heat perishable fruits and vegetables also have a reduced shelf life so vendors are unable to capitalize on whatever produce they do havethe state has recently announced a stimulus package of inr  crore for nearly  lakh vendors acknowledging the grave impact of their loss of livelihood the intended relief for vendors will be a credit loan that will provide an initial working capital of inr  for all vendors but this is not sufficient instead of credit the government should think of converting it into direct income benefit a cash grant as livelihood support to start the income activity regularly the vendors need income support to be able to restart work and if they are not able to do so how will they return the loan in the face of the everchanging crisis vendor organizations have to step forward and advocate for vendors to be provided the resources they need to be able to resume their livelihoods to this end vendors organizations could consider the following for an advocacy agenda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][169]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc02e4",
   "metadata": {},
   "source": [
    "### tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "129458af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the word using nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "clean_data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bdc6f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(clean_data['text'])):\n",
    "    clean_data['text'][i] = word_tokenize(clean_data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f8aa25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[how, artificial, intelligence, can, boost, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[how, does, ai, help, to, monitor, retail, she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[how, are, genetic, sequencing, maps, affected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ai, and, its, impact, on, the, fashion, indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[benefits, of, big, data, in, different, field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[how, artificial, intelligence, can, deliver, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[role, of, big, data, in, academia, blackcoffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[what, is, data, exfiltration, blackcoffer, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[methods, for, sales, forecasting, in, retail,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[impacts, of, covid, on, food, products, black...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    [how, artificial, intelligence, can, boost, yo...\n",
       "1    [how, does, ai, help, to, monitor, retail, she...\n",
       "2    [how, are, genetic, sequencing, maps, affected...\n",
       "3    [ai, and, its, impact, on, the, fashion, indus...\n",
       "4    [benefits, of, big, data, in, different, field...\n",
       "..                                                 ...\n",
       "165  [how, artificial, intelligence, can, deliver, ...\n",
       "166  [role, of, big, data, in, academia, blackcoffe...\n",
       "167  [what, is, data, exfiltration, blackcoffer, in...\n",
       "168  [methods, for, sales, forecasting, in, retail,...\n",
       "169  [impacts, of, covid, on, food, products, black...\n",
       "\n",
       "[170 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac4f73",
   "metadata": {},
   "source": [
    "## removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdacce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380c5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data['text']=clean_data['text'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38934890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data['text'][166])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caffe3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [artificial, intelligence, boost, productivity...\n",
       "1      [ai, help, monitor, retail, shelf, watches, bl...\n",
       "2      [genetic, sequencing, maps, affected, deep, le...\n",
       "3      [ai, impact, fashion, industry, blackcoffer, i...\n",
       "4      [benefits, big, data, different, fields, black...\n",
       "                             ...                        \n",
       "165    [artificial, intelligence, deliver, real, valu...\n",
       "166    [role, big, data, academia, blackcoffer, insig...\n",
       "167    [data, exfiltration, blackcoffer, insightsif, ...\n",
       "168    [methods, sales, forecasting, retail, blackcof...\n",
       "169    [impacts, covid, food, products, blackcoffer, ...\n",
       "Name: text, Length: 170, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fcac07",
   "metadata": {},
   "source": [
    "### lemmantization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2432a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "cleans_data=clean_data.copy()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \"\".join([lemmatizer.lemmatize(w) for w in text]) \n",
    "\n",
    "for i in range(0, 169):\n",
    "    for j in range(0,len(clean_data['text'][i])-1):\n",
    "        cleans_data['text'][i][j-1]=lemmatize_text(clean_data['text'][i][j-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34aafbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[artificial, intelligence, boost, productivity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ai, help, monitor, retail, shelf, watches, bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[genetic, sequencing, maps, affected, deep, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ai, impact, fashion, industry, blackcoffer, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[benefits, big, data, different, fields, black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[artificial, intelligence, deliver, real, valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[role, big, data, academia, blackcoffer, insig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[data, exfiltration, blackcoffer, insightsif, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[methods, sales, forecasting, retail, blackcof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[impacts, covid, food, products, blackcoffer, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    [artificial, intelligence, boost, productivity...\n",
       "1    [ai, help, monitor, retail, shelf, watches, bl...\n",
       "2    [genetic, sequencing, maps, affected, deep, le...\n",
       "3    [ai, impact, fashion, industry, blackcoffer, i...\n",
       "4    [benefits, big, data, different, fields, black...\n",
       "..                                                 ...\n",
       "165  [artificial, intelligence, deliver, real, valu...\n",
       "166  [role, big, data, academia, blackcoffer, insig...\n",
       "167  [data, exfiltration, blackcoffer, insightsif, ...\n",
       "168  [methods, sales, forecasting, retail, blackcof...\n",
       "169  [impacts, covid, food, products, blackcoffer, ...\n",
       "\n",
       "[170 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cleans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65ca93d",
   "metadata": {},
   "source": [
    "### creating positive negative and polarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae25b734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4dd2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_neg_analyze(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['neg']\n",
    "def sentiment_pos_analyze(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['pos']\n",
    "def sentiment_neu_analyze(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['neu']\n",
    "cleans_data['neg']=0\n",
    "cleans_data['pos']=0\n",
    "cleans_data['neu']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9149a38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most time taker function\n",
    "for i in range(0,169):\n",
    "    neg=0\n",
    "    pos=0\n",
    "    neu=0\n",
    "    for j in range(0,len(clean_data['text'][i])):\n",
    "         neg += sentiment_neg_analyze(cleans_data['text'][i][j])\n",
    "         pos += sentiment_pos_analyze(cleans_data['text'][i][j])\n",
    "         neu += sentiment_neu_analyze(cleans_data['text'][i][j])\n",
    "    cleans_data['neg'][i]=neg\n",
    "    cleans_data['pos'][i]=pos\n",
    "    cleans_data['neu'][i]=neu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95e45057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[artificial, intelligence, boost, productivity...</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ai, help, monitor, retail, shelf, watches, bl...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[genetic, sequencing, maps, affected, deep, le...</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ai, impact, fashion, industry, blackcoffer, i...</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[benefits, big, data, different, fields, black...</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  neg  pos  neu\n",
       "0  [artificial, intelligence, boost, productivity...    5   30  327\n",
       "1  [ai, help, monitor, retail, shelf, watches, bl...   11   34  331\n",
       "2  [genetic, sequencing, maps, affected, deep, le...    7   46  622\n",
       "3  [ai, impact, fashion, industry, blackcoffer, i...   12   85  901\n",
       "4  [benefits, big, data, different, fields, black...   15   69  660"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleans_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b62b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating two columns float type for polarity\n",
    "cleans_data['polarity']=0\n",
    "cleans_data['subjective']=0\n",
    "cleans_data['polarity']=pd.to_numeric(cleans_data[\"polarity\"], downcast=\"float\")\n",
    "cleans_data['subjective']=pd.to_numeric(cleans_data[\"subjective\"], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70559357",
   "metadata": {},
   "source": [
    "### formula for the polarity and subjective"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d50afc",
   "metadata": {},
   "source": [
    "(Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "160ba283",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,169):\n",
    "    cleans_data['polarity'][i]=(cleans_data['pos'][i]-cleans_data['neg'][i])/((cleans_data['pos'][i]+cleans_data['neg'][i])+0.000001)\n",
    "for i in range(0,169):\n",
    "    cleans_data['subjective'][i]=(cleans_data['pos'][i] + cleans_data['neg'][i])/(len(cleans_data['text'][i]) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0464b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[artificial, intelligence, boost, productivity...</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>327</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ai, help, monitor, retail, shelf, watches, bl...</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>331</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.118421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[genetic, sequencing, maps, affected, deep, le...</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>622</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.076369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ai, impact, fashion, industry, blackcoffer, i...</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "      <td>901</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.094175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[benefits, big, data, different, fields, black...</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>660</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.111406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[artificial, intelligence, deliver, real, valu...</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>733</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.116390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[role, big, data, academia, blackcoffer, insig...</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>730</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.080247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[data, exfiltration, blackcoffer, insightsif, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>245</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.050193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>[methods, sales, forecasting, retail, blackcof...</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>382</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.113122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>[impacts, covid, food, products, blackcoffer, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  neg  pos  neu  \\\n",
       "0    [artificial, intelligence, boost, productivity...    5   30  327   \n",
       "1    [ai, help, monitor, retail, shelf, watches, bl...   11   34  331   \n",
       "2    [genetic, sequencing, maps, affected, deep, le...    7   46  622   \n",
       "3    [ai, impact, fashion, industry, blackcoffer, i...   12   85  901   \n",
       "4    [benefits, big, data, different, fields, black...   15   69  660   \n",
       "..                                                 ...  ...  ...  ...   \n",
       "165  [artificial, intelligence, deliver, real, valu...   14   84  733   \n",
       "166  [role, big, data, academia, blackcoffer, insig...   14   51  730   \n",
       "167  [data, exfiltration, blackcoffer, insightsif, ...    6    7  245   \n",
       "168  [methods, sales, forecasting, retail, blackcof...   17   33  382   \n",
       "169  [impacts, covid, food, products, blackcoffer, ...    0    0    0   \n",
       "\n",
       "     polarity  subjective  \n",
       "0    0.714286    0.096154  \n",
       "1    0.511111    0.118421  \n",
       "2    0.735849    0.076369  \n",
       "3    0.752577    0.094175  \n",
       "4    0.642857    0.111406  \n",
       "..        ...         ...  \n",
       "165  0.714286    0.116390  \n",
       "166  0.569231    0.080247  \n",
       "167  0.076923    0.050193  \n",
       "168  0.320000    0.113122  \n",
       "169  0.000000    0.000000  \n",
       "\n",
       "[170 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd4b9c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_data=cleans_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2c283b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.insert(0,'Text',df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5792c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['average_sentence_length']=0\n",
    "cleaned_data['syllabe_word']=0\n",
    "cleaned_data['fog_index']=0\n",
    "cleaned_data['average_sentence_length']=pd.to_numeric(cleaned_data[\"average_sentence_length\"], downcast=\"float\")\n",
    "cleaned_data['syllabe_word']=pd.to_numeric(cleaned_data[\"syllabe_word\"], downcast=\"float\")\n",
    "cleaned_data['fog_index']=pd.to_numeric(cleaned_data[\"fog_index\"], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff25da8",
   "metadata": {},
   "source": [
    "###  Word Count and sentence count for the fog index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2fa8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def sentence_coutn(sentences):\n",
    "    number_of_sentences = sent_tokenize(sentences)\n",
    "    return len(number_of_sentences)\n",
    "def word_count(c):\n",
    "    return len(c.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "653b222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,169):\n",
    "    cleaned_data['average_sentence_length'][i]=(word_count(cleaned_data['Text'][i]))/(sentence_coutn(cleaned_data['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e7cabce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      21.281250\n",
       "1      29.809525\n",
       "2      29.184210\n",
       "3      43.487179\n",
       "4      36.411766\n",
       "         ...    \n",
       "165    27.830189\n",
       "166    30.617022\n",
       "167    22.571428\n",
       "168    31.727272\n",
       "169     0.000000\n",
       "Name: average_sentence_length, Length: 170, dtype: float32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['average_sentence_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a52175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
